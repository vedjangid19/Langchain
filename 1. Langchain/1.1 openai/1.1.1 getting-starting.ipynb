{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Important components of langchain\n",
    "\n",
    "1. Get set up langchain, langSmith and langserve\n",
    "2. use the most basic and common component of langchain is prompt template, models and output parsers\n",
    "3. build a simple application with langchain\n",
    "4. Trace your application with langsmith\n",
    "5. serve application with langserve\n",
    "\n",
    "all llm requests and chat is record on langsmith go to Langsmith and check your project logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000208BA41BC40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000208BB929840>, root_client=<openai.OpenAI object at 0x00000208BB7A33A0>, root_async_client=<openai.AsyncOpenAI object at 0x00000208BB7E7CD0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a category of artificial intelligence algorithms and models designed to generate new content or data that resembles existing data. This type of AI can create text, images, music, video, and more, often with impressive levels of realism and coherence.\\n\\nSome key characteristics and components of generative AI include:\\n\\n1. **Generative Models**: These are algorithms that learn from a dataset and can generate new instances that resemble the training data. Common types of generative models include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based models.\\n\\n2. **Applications**: Generative AI has a wide range of applications, such as content creation (writing articles, generating images or video), design (creating prototypes or artwork), and simulation (generating realistic scenarios for training or testing).\\n\\n3. **Natural Language Processing (NLP)**: In the realm of text, models like OpenAI's GPT (Generative Pre-trained Transformer) are used to generate human-like text, answer questions, and assist with various language-related tasks.\\n\\n4. **Image and Video Generation**: GANs, for example, have been used to generate realistic images, create deepfake videos, and enhance image resolution.\\n\\n5. **Music and Audio**: Generative AI can compose music or generate realistic sound effects.\\n\\n6. **Challenges**: While generative AI holds great promise, it also presents challenges, such as potential misuse (e.g., creating deepfakes), ethical concerns, and the quality and bias of generated content.\\n\\nOverall, generative AI represents a significant advancement in the field of AI, enabling machines to create novel content that can enhance creativity, productivity, and innovation across various domains.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 348, 'prompt_tokens': 13, 'total_tokens': 361, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_45cf54deae', 'finish_reason': 'stop', 'logprobs': None} id='run-1465c744-b946-4ab5-a50d-9e7c036f4424-0' usage_metadata={'input_tokens': 13, 'output_tokens': 348, 'total_tokens': 361, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Template Prompt\n",
    "\n",
    "prompt template is like how you want your LLM model to behave or what kind of response or what kind of role you really want to give your LLM model.\n",
    "Eg. act as an AI engineer and provide me suggestion how to develop an amazing AI project.\n",
    "\n",
    "Langchain also support the different type of chat prompt template.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are an expert AI Engineer, provide me answer based on the question.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an expert AI Engineer, provide me answer based on the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create chains\n",
    "\n",
    "so chain basically means you can combine multiple things like prompt you can combine llm create your arm custom probe custom prompt.\n",
    "Based on that, it just give you a an idea like how once the input is given by the user. how the flow is you know initially IT will go to prompt template then it will go to the LLM.\n",
    "\n",
    "I really want to make sure that I probably can use some kind of outpur parser also display my response output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|llm\n",
    "\n",
    "chain_response = chain.invoke(\n",
    "    {\n",
    "        \"input\": \"Can you tell me about langsmith?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangSmith is a tool developed by LangChain, designed to enhance the development and deployment of applications that utilize large language models (LLMs). It provides a suite of features aimed at improving the debugging, testing, evaluation, and monitoring processes for LLM-based applications.\\n\\nKey features of LangSmith include:\\n\\n1. **Debugging**: LangSmith provides tools to help developers identify and fix issues in their LLM applications, allowing for more efficient troubleshooting and optimization.\\n\\n2. **Testing**: The platform offers capabilities to test applications in various scenarios to ensure they perform as expected under different conditions, helping to validate their reliability and robustness.\\n\\n3. **Evaluation**: LangSmith includes tools for evaluating the performance of LLM applications, providing metrics and insights that help developers understand how well their models are functioning.\\n\\n4. **Monitoring**: It enables continuous monitoring of applications in production, allowing developers to track performance, detect anomalies, and make necessary adjustments in real-time.\\n\\nOverall, LangSmith is geared toward making the process of building and maintaining LLM applications more streamlined and effective, catering to the needs of developers seeking to leverage the power of language models in practical applications.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 232, 'prompt_tokens': 34, 'total_tokens': 266, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7193b6e18f', 'finish_reason': 'stop', 'logprobs': None} id='run-69d50153-cdc8-48b1-9d3c-38d49cd28d6e-0' usage_metadata={'input_tokens': 34, 'output_tokens': 232, 'total_tokens': 266, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(chain_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "output_parser_chain = prompt | llm | output_parser\n",
    "\n",
    "output_chain_response = output_parser_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What is scope and future of GenAI?\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The scope and future of Generative AI (GenAI) are expansive and promising, with potential impacts across numerous industries and applications. Here are some key aspects to consider:\\n\\n1. **Creative Industries**: GenAI is revolutionizing fields like art, music, and content creation by enabling artists and creators to generate new works, explore novel ideas, and automate repetitive tasks. Tools like DALL-E and GPT models are becoming integral in these industries.\\n\\n2. **Healthcare**: In healthcare, GenAI can assist in drug discovery, personalized medicine, and diagnostic imaging. By generating synthetic data, it can also help in research and overcoming data scarcity issues.\\n\\n3. **Business and Automation**: Organizations are leveraging GenAI for automating customer service through chatbots, generating reports, and even creating marketing content. This leads to increased efficiency and cost savings.\\n\\n4. **Education**: GenAI can personalize learning experiences, generate educational content, and provide tutoring assistance, making education more accessible and tailored to individual needs.\\n\\n5. **Software Development**: Tools like GitHub Copilot showcase GenAI's potential to assist developers by writing code, suggesting improvements, and even automating mundane coding tasks.\\n\\n6. **Ethics and Regulation**: As GenAI becomes more prevalent, issues surrounding ethics, bias, and data privacy will need careful attention. Regulatory frameworks will evolve to address these concerns and ensure responsible use.\\n\\n7. **Research and Development**: GenAI will continue to be a focus in AI research, driving advancements in machine learning algorithms, model efficiency, and understanding of AI interpretability and explainability.\\n\\n8. **Economic Impact**: The economic impact of GenAI could be substantial, with new business models emerging and existing industries being disrupted. This will lead to job transformation and the creation of new roles focused on AI oversight and management.\\n\\n9. **Interdisciplinary Applications**: GenAI's capabilities will expand as it is integrated into other technologies like IoT, blockchain, and quantum computing, resulting in innovative interdisciplinary applications.\\n\\nOverall, the future of GenAI is bright, with the potential to transform how we work, create, and interact with technology. However, realizing this potential will require addressing ethical concerns, ensuring transparency, and fostering a collaborative approach between humans and AI.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
