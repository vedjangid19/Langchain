{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"Simple_GENAI_APP\"\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['USER_AGENT'] = 'myagent'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding Transformers: A Simplified Guide with Easy-to-Understand ExamplesAsimsultan (Head of AI)·Follow4 min read·Aug 29, 2024--ListenShareThe Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind Transformers can seem complex at first. In this guide, we’ll break down the key ideas using simple, relatable examples that make the mechanics of Transformers easy to grasp.What Are Transformers?Transformers are a type of AI model that excel at processing sequences of data, such as sentences in a text. They differ from earlier models like Recurrent Neural Networks (RNNs) by processing all elements of the sequence simultaneously, rather than one by one. This parallel processing is enabled by the attention mechanism, which helps the model focus on the most relevant parts of the sequence at each step.The Attention MechanismLet’s start with the attention mechanism, the heart of the Transformer. To understand this, think about how you focus on different words in a sentence when trying to understand its meaning. If you hear the sentence:“The dog barked loudly at the stranger.”You naturally focus on “dog” when you hear “barked” because the action is directly related to the dog. This is similar to how the attention mechanism works in a Transformer.Example: The “Shopping List” AnalogyImagine you have a shopping list with the following items:EggsMilkBreadButterCheeseNow, suppose you want to prepare a sandwich. You’ll focus more on items like bread, cheese, and butter than on eggs and milk because they are more relevant to making a sandwich. This is what the attention mechanism does — it determines which parts of the input (your shopping list) are most important for the task at hand (making a sandwich).In a sentence like:“The cat chased the mouse.”When the model focuses on “chased,” it assigns more attention to “cat” and “mouse” because they are directly involved in the action.Multi-Head AttentionNow, let’s dive into multi-head attention. Think of it as getting multiple perspectives on the same situation. Each “head” in the multi-head attention mechanism looks at different aspects of the sentence.Example: The “Detective Team” AnalogyImagine you have a team of detectives investigating a crime. Each detective specializes in a different area:Detective 1 looks at the relationships between suspects.Detective 2 focuses on the timeline of events.Detective 3 examines physical evidence.By combining their findings, you get a more complete understanding of the case. Similarly, each head in the multi-head attention mechanism looks at different relationships between words in a sentence. One head might focus on the subject-verb relationship (like “cat” and “chased”), while another head might focus on the object (like “mouse”).For example, in the sentence:“The quick brown fox jumps over the lazy dog.”One attention head might focus on how “quick” describes “fox,” while another might focus on the relationship between “jumps” and “over.”Positional EncodingTransformers process all words in a sentence simultaneously, so they need a way to understand the order of words — this is where positional encoding comes in. Positional encoding adds a unique identifier to each word based on its position in the sentence.Example: The “Classroom Roll Call” AnalogyImagine you’re in a classroom where students are called on by their seat number rather than their name. Even if two students have the same name, the teacher can still distinguish between them based on their seat number.Similarly, in a sentence, positional encoding helps the Transformer differentiate between words based on their position. For instance, in the sentences:“The cat sat on the mat.”“On the mat sat the cat.”Although both sentences contain the same words, positional encoding helps the model understand that “sat” relates differently to “cat” in each sentence.Putting It All TogetherLet’s walk through how a Transformer processes a simple sentence:Sentence: “The red ball bounced.”Tokenization: The sentence is broken down into tokens (words or subwords). For example:“The” -> [0.2, 0.4, 0.6, …]“red” -> [0.8, 0.5, 0.3, …]“ball” -> [0.7, 0.1, 0.9, …]“bounced” -> [0.3, 0.9, 0.5, …]2. Positional Encoding: Positional encoding vectors are added to these word vectors to give the model a sense of word order.3. Attention Mechanism: The model generates Query, Key, and Value vectors for each word. It calculates attention scores to determine how much focus each word should have on the others. For example, “bounced” might focus on “ball” because they are directly related.4. Multi-Head Attention: Multiple attention heads process the sentence, each focusing on different relationships. One head might pay attention to the color “red” and the object “ball,” while another might focus on the action “bounced.”5. Output: The final output is a detailed representation of the sentence that captures both the meaning of individual words and the relationships between them.ConclusionTransformers have revolutionized how we approach language processing tasks by introducing a model that can handle complex dependencies and relationships in text more effectively than previous models. By using easy-to-understand analogies and examples, we hope this guide has demystified the inner workings of Transformers. Whether you’re new to NLP or looking to deepen your understanding, grasping these fundamental concepts is key to unlocking the full potential of Transformers in AI.TransformersLlmLarge Language ModelsMachine LearningData Science----FollowWritten by Asimsultan (Head of AI)16 Followers·1 FollowingLLM enthusiast with expertise in fine-tuning and deploying models. Passionate about AI, NLP, and sharing knowledge through detailed guides and content.FollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Ingestion\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848\")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | MediumOpen in appSign upSign inWriteSign upSign inUnderstanding Transformers: A Simplified Guide with Easy-to-Understand ExamplesAsimsultan (Head of AI)·Follow4 min read·Aug 29, 2024--ListenShareThe Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='human language. However, the concepts behind Transformers can seem complex at first. In this guide, we’ll break down the key ideas using simple, relatable examples that make the mechanics of Transformers easy to grasp.What Are Transformers?Transformers are a type of AI model that excel at processing sequences of data, such as sentences in a text. They differ from earlier models like Recurrent Neural Networks (RNNs) by processing all elements of the sequence simultaneously, rather than one by'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='the sequence simultaneously, rather than one by one. This parallel processing is enabled by the attention mechanism, which helps the model focus on the most relevant parts of the sequence at each step.The Attention MechanismLet’s start with the attention mechanism, the heart of the Transformer. To understand this, think about how you focus on different words in a sentence when trying to understand its meaning. If you hear the sentence:“The dog barked loudly at the stranger.”You naturally focus'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='loudly at the stranger.”You naturally focus on “dog” when you hear “barked” because the action is directly related to the dog. This is similar to how the attention mechanism works in a Transformer.Example: The “Shopping List” AnalogyImagine you have a shopping list with the following items:EggsMilkBreadButterCheeseNow, suppose you want to prepare a sandwich. You’ll focus more on items like bread, cheese, and butter than on eggs and milk because they are more relevant to making a sandwich. This'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='they are more relevant to making a sandwich. This is what the attention mechanism does — it determines which parts of the input (your shopping list) are most important for the task at hand (making a sandwich).In a sentence like:“The cat chased the mouse.”When the model focuses on “chased,” it assigns more attention to “cat” and “mouse” because they are directly involved in the action.Multi-Head AttentionNow, let’s dive into multi-head attention. Think of it as getting multiple perspectives on'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='Think of it as getting multiple perspectives on the same situation. Each “head” in the multi-head attention mechanism looks at different aspects of the sentence.Example: The “Detective Team” AnalogyImagine you have a team of detectives investigating a crime. Each detective specializes in a different area:Detective 1 looks at the relationships between suspects.Detective 2 focuses on the timeline of events.Detective 3 examines physical evidence.By combining their findings, you get a more complete'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='combining their findings, you get a more complete understanding of the case. Similarly, each head in the multi-head attention mechanism looks at different relationships between words in a sentence. One head might focus on the subject-verb relationship (like “cat” and “chased”), while another head might focus on the object (like “mouse”).For example, in the sentence:“The quick brown fox jumps over the lazy dog.”One attention head might focus on how “quick” describes “fox,” while another might'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='how “quick” describes “fox,” while another might focus on the relationship between “jumps” and “over.”Positional EncodingTransformers process all words in a sentence simultaneously, so they need a way to understand the order of words — this is where positional encoding comes in. Positional encoding adds a unique identifier to each word based on its position in the sentence.Example: The “Classroom Roll Call” AnalogyImagine you’re in a classroom where students are called on by their seat number'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='where students are called on by their seat number rather than their name. Even if two students have the same name, the teacher can still distinguish between them based on their seat number.Similarly, in a sentence, positional encoding helps the Transformer differentiate between words based on their position. For instance, in the sentences:“The cat sat on the mat.”“On the mat sat the cat.”Although both sentences contain the same words, positional encoding helps the model understand that “sat”'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='encoding helps the model understand that “sat” relates differently to “cat” in each sentence.Putting It All TogetherLet’s walk through how a Transformer processes a simple sentence:Sentence: “The red ball bounced.”Tokenization: The sentence is broken down into tokens (words or subwords). For example:“The” -> [0.2, 0.4, 0.6, …]“red” -> [0.8, 0.5, 0.3, …]“ball” -> [0.7, 0.1, 0.9, …]“bounced” -> [0.3, 0.9, 0.5, …]2. Positional Encoding: Positional encoding vectors are added to these word vectors'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='encoding vectors are added to these word vectors to give the model a sense of word order.3. Attention Mechanism: The model generates Query, Key, and Value vectors for each word. It calculates attention scores to determine how much focus each word should have on the others. For example, “bounced” might focus on “ball” because they are directly related.4. Multi-Head Attention: Multiple attention heads process the sentence, each focusing on different relationships. One head might pay attention to'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='relationships. One head might pay attention to the color “red” and the object “ball,” while another might focus on the action “bounced.”5. Output: The final output is a detailed representation of the sentence that captures both the meaning of individual words and the relationships between them.ConclusionTransformers have revolutionized how we approach language processing tasks by introducing a model that can handle complex dependencies and relationships in text more effectively than previous'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='in text more effectively than previous models. By using easy-to-understand analogies and examples, we hope this guide has demystified the inner workings of Transformers. Whether you’re new to NLP or looking to deepen your understanding, grasping these fundamental concepts is key to unlocking the full potential of Transformers in AI.TransformersLlmLarge Language ModelsMachine LearningData Science----FollowWritten by Asimsultan (Head of AI)16 Followers·1 FollowingLLM enthusiast with expertise in'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='FollowingLLM enthusiast with expertise in fine-tuning and deploying models. Passionate about AI, NLP, and sharing knowledge through detailed guides and content.FollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split document into small document chunk\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x0000028951919900>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x0000028953449D80>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embedding\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x28969d1c9a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstoredb = FAISS.from_documents(split_docs, embeddings)\n",
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstoredb.save_local(\"./simple_genai_faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='combining their findings, you get a more complete understanding of the case. Similarly, each head in the multi-head attention mechanism looks at different relationships between words in a sentence. One head might focus on the subject-verb relationship (like “cat” and “chased”), while another head might focus on the object (like “mouse”).For example, in the sentence:“The quick brown fox jumps over the lazy dog.”One attention head might focus on how “quick” describes “fox,” while another might'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='Think of it as getting multiple perspectives on the same situation. Each “head” in the multi-head attention mechanism looks at different aspects of the sentence.Example: The “Detective Team” AnalogyImagine you have a team of detectives investigating a crime. Each detective specializes in a different area:Detective 1 looks at the relationships between suspects.Detective 2 focuses on the timeline of events.Detective 3 examines physical evidence.By combining their findings, you get a more complete'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='they are more relevant to making a sandwich. This is what the attention mechanism does — it determines which parts of the input (your shopping list) are most important for the task at hand (making a sandwich).In a sentence like:“The cat chased the mouse.”When the model focuses on “chased,” it assigns more attention to “cat” and “mouse” because they are directly involved in the action.Multi-Head AttentionNow, let’s dive into multi-head attention. Think of it as getting multiple perspectives on'),\n",
       " Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='the sequence simultaneously, rather than one by one. This parallel processing is enabled by the attention mechanism, which helps the model focus on the most relevant parts of the sequence at each step.The Attention MechanismLet’s start with the attention mechanism, the heart of the Transformer. To understand this, think about how you focus on different words in a sentence when trying to understand its meaning. If you hear the sentence:“The dog barked loudly at the stranger.”You naturally focus')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity search\n",
    "\n",
    "result_responses = vectorstoredb.similarity_search(query=\"let’s dive into multi-head attention\")\n",
    "result_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combining their findings, you get a more complete understanding of the case. Similarly, each head in the multi-head attention mechanism looks at different relationships between words in a sentence. One head might focus on the subject-verb relationship (like “cat” and “chased”), while another head might focus on the object (like “mouse”).For example, in the sentence:“The quick brown fox jumps over the lazy dog.”One attention head might focus on how “quick” describes “fox,” while another might'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_responses[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the following questions based only on provided context:\\n    <context>\\n    {context} \\n    </context>\\n\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002897E89F5B0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002897E8C0BE0>, root_client=<openai.OpenAI object at 0x000002895341FB50>, root_async_client=<openai.AsyncOpenAI object at 0x000002897E89F610>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the following questions based only on provided context:\n",
    "    <context>\n",
    "    {context} \n",
    "    </context>\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here are some answers based on the provided context:\\n\\n1. **What is multi-head attention?**\\n   - Multi-head attention is a mechanism that provides multiple perspectives on the same situation by using multiple \"heads\" to examine different aspects of a sentence.\\n\\n2. **What does each “head” in multi-head attention do?**\\n   - Each \"head\" in the multi-head attention mechanism looks at different aspects of the sentence, providing diverse insights or perspectives.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"let’s dive into multi-head attention\",\n",
    "        \"context\": [Document(page_content=\"let’s dive into multi-head attention. Think of it as getting multiple perspectives on the same situation. Each “head” in the multi-head attention mechanism looks at different aspects of the sentence.\")]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000028969D1C9A0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the following questions based only on provided context:\\n    <context>\\n    {context} \\n    </context>\\n\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002897E89F5B0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002897E8C0BE0>, root_client=<openai.OpenAI object at 0x000002895341FB50>, root_async_client=<openai.AsyncOpenAI object at 0x000002897E89F610>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever\n",
    "retriever = vectorstoredb.as_retriever()\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever_chain = create_retrieval_chain(retriever, document_chain)\n",
    "retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_response = retriever_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What is Positional Encoding?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Positional Encoding?',\n",
       " 'context': [Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='how “quick” describes “fox,” while another might focus on the relationship between “jumps” and “over.”Positional EncodingTransformers process all words in a sentence simultaneously, so they need a way to understand the order of words — this is where positional encoding comes in. Positional encoding adds a unique identifier to each word based on its position in the sentence.Example: The “Classroom Roll Call” AnalogyImagine you’re in a classroom where students are called on by their seat number'),\n",
       "  Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='where students are called on by their seat number rather than their name. Even if two students have the same name, the teacher can still distinguish between them based on their seat number.Similarly, in a sentence, positional encoding helps the Transformer differentiate between words based on their position. For instance, in the sentences:“The cat sat on the mat.”“On the mat sat the cat.”Although both sentences contain the same words, positional encoding helps the model understand that “sat”'),\n",
       "  Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='encoding helps the model understand that “sat” relates differently to “cat” in each sentence.Putting It All TogetherLet’s walk through how a Transformer processes a simple sentence:Sentence: “The red ball bounced.”Tokenization: The sentence is broken down into tokens (words or subwords). For example:“The” -> [0.2, 0.4, 0.6, …]“red” -> [0.8, 0.5, 0.3, …]“ball” -> [0.7, 0.1, 0.9, …]“bounced” -> [0.3, 0.9, 0.5, …]2. Positional Encoding: Positional encoding vectors are added to these word vectors'),\n",
       "  Document(metadata={'source': 'https://medium.com/@asimsultan2/understanding-transformers-a-simplified-guide-with-easy-to-understand-examples-227fd8d31848', 'title': 'Understanding Transformers: A Simplified Guide with Easy-to-Understand Examples | by Asimsultan (Head of AI) | Medium', 'description': 'The Transformer architecture is a powerful model in natural language processing (NLP) that has revolutionized how machines understand and generate human language. However, the concepts behind…', 'language': 'en'}, page_content='encoding vectors are added to these word vectors to give the model a sense of word order.3. Attention Mechanism: The model generates Query, Key, and Value vectors for each word. It calculates attention scores to determine how much focus each word should have on the others. For example, “bounced” might focus on “ball” because they are directly related.4. Multi-Head Attention: Multiple attention heads process the sentence, each focusing on different relationships. One head might pay attention to')],\n",
       " 'answer': '1. What is the purpose of positional encoding in a Transformer model?\\n\\n   Positional encoding is used to help the Transformer model understand the order of words in a sentence. Since Transformers process all words simultaneously, positional encoding adds a unique identifier to each word based on its position in the sentence, allowing the model to differentiate between words and their relationships based on their position.\\n\\n2. How does positional encoding help in differentiating between words with the same meaning but in different positions?\\n\\n   Positional encoding helps differentiate words with the same meaning but in different positions by providing a unique positional identifier to each word. This allows the model to understand how the same words relate differently in sentences with different structures, like \"The cat sat on the mat\" and \"On the mat sat the cat.\"\\n\\n3. Describe the tokenization process in the context of a Transformer model.\\n\\n   In a Transformer model, tokenization is the process of breaking down a sentence into tokens, which could be words or subwords. Each token is then represented by a vector. For example, the sentence \"The red ball bounced\" is tokenized into \"The,\" \"red,\" \"ball,\" and \"bounced,\" with each token being assigned a corresponding vector.\\n\\n4. What role does the attention mechanism play in a Transformer model?\\n\\n   The attention mechanism in a Transformer model generates Query, Key, and Value vectors for each word in the sentence. It calculates attention scores to determine how much focus each word should have on the others. This helps the model understand which words in the sentence are more relevant or related to each other, such as focusing on \"bounced\" in relation to \"ball.\"\\n\\n5. Explain the concept of multi-head attention in the Transformer model.\\n\\n   Multi-head attention refers to the use of multiple attention heads in a Transformer model, where each head processes the sentence focusing on different relationships between words. Each head can attend to different aspects or parts of the sentence, allowing the model to capture a variety of linguistic relationships and nuances simultaneously.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is the purpose of positional encoding in a Transformer model?\n",
      "\n",
      "   Positional encoding is used to help the Transformer model understand the order of words in a sentence. Since Transformers process all words simultaneously, positional encoding adds a unique identifier to each word based on its position in the sentence, allowing the model to differentiate between words and their relationships based on their position.\n",
      "\n",
      "2. How does positional encoding help in differentiating between words with the same meaning but in different positions?\n",
      "\n",
      "   Positional encoding helps differentiate words with the same meaning but in different positions by providing a unique positional identifier to each word. This allows the model to understand how the same words relate differently in sentences with different structures, like \"The cat sat on the mat\" and \"On the mat sat the cat.\"\n",
      "\n",
      "3. Describe the tokenization process in the context of a Transformer model.\n",
      "\n",
      "   In a Transformer model, tokenization is the process of breaking down a sentence into tokens, which could be words or subwords. Each token is then represented by a vector. For example, the sentence \"The red ball bounced\" is tokenized into \"The,\" \"red,\" \"ball,\" and \"bounced,\" with each token being assigned a corresponding vector.\n",
      "\n",
      "4. What role does the attention mechanism play in a Transformer model?\n",
      "\n",
      "   The attention mechanism in a Transformer model generates Query, Key, and Value vectors for each word in the sentence. It calculates attention scores to determine how much focus each word should have on the others. This helps the model understand which words in the sentence are more relevant or related to each other, such as focusing on \"bounced\" in relation to \"ball.\"\n",
      "\n",
      "5. Explain the concept of multi-head attention in the Transformer model.\n",
      "\n",
      "   Multi-head attention refers to the use of multiple attention heads in a Transformer model, where each head processes the sentence focusing on different relationships between words. Each head can attend to different aspects or parts of the sentence, allowing the model to capture a variety of linguistic relationships and nuances simultaneously.\n"
     ]
    }
   ],
   "source": [
    "print(retriever_response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
