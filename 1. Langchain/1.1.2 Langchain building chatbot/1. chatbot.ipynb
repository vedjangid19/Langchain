{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001BAF9362860>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001BAF93615A0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ved Sharma! It's a pleasure to meet you. \\n\\nBeing a Chief AI Engineer is a fascinating role. What kind of work are you currently involved in?  \\n\\nAre you working on any particularly exciting projects you'd like to talk about? I'm always interested in learning more about the latest advancements in AI.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 25, 'total_tokens': 96, 'completion_time': 0.129090909, 'prompt_time': 0.000150839, 'queue_time': 0.013641201, 'total_time': 0.129241748}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8f51afcf-7b69-4093-b519-b350c5140361-0', usage_metadata={'input_tokens': 25, 'output_tokens': 71, 'total_tokens': 96})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response1 = model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"HI, My name is ved Sharma and i am a cheif ai engineer.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Ved Sharma and that you are a Chief AI Engineer.  \\n\\nIs there anything else you'd like to tell me about yourself or your work? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 102, 'total_tokens': 143, 'completion_time': 0.074545455, 'prompt_time': 0.003472357, 'queue_time': 0.010964482, 'total_time': 0.078017812}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4b844471-4cc1-43a1-b3d0-2f5cf71160c5-0', usage_metadata={'input_tokens': 102, 'output_tokens': 41, 'total_tokens': 143})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "response2 = model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"HI, My name is ved Sharma and i am a cheif ai engineer.\"),\n",
    "        AIMessage(content=\"Hello Ved Sharma,\\n\\nIt's nice to meet you!  Being a Chief AI Engineer is a fascinating role. What kind of projects are you working on these days?  \\n\\nI'm always eager to learn more about the advancements being made in the field of AI.\\n\"),\n",
    "        HumanMessage(content=\"What's my Name and what i do?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ved Sharma, it's nice to meet you!  Being a Chief AI Engineer is a fascinating role. What kind of projects are you working on these days? \\n\\nI'm always eager to learn more about the exciting work being done in the field of AI.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 25, 'total_tokens': 84, 'completion_time': 0.107272727, 'prompt_time': 0.000152149, 'queue_time': 0.013585858999999999, 'total_time': 0.107424876}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b5205418-eff6-41c0-a99d-6e9f0ad5f5d6-0', usage_metadata={'input_tokens': 25, 'output_tokens': 59, 'total_tokens': 84})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat-1\"}}\n",
    "\n",
    "response3 = with_message_history.invoke(\n",
    "    HumanMessage(content=\"HI, My name is ved Sharma and i am a cheif ai engineer.\"),\n",
    "    config=config\n",
    ")\n",
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ved Sharma.  \\n\\nI remembered it from our introduction! üòä  Is there anything else I can help you with? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 98, 'total_tokens': 129, 'completion_time': 0.056363636, 'prompt_time': 0.00255754, 'queue_time': 0.012996429, 'total_time': 0.058921176}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c5c645e7-417a-4c1b-bc1a-9ed2094ceaf6-0', usage_metadata={'input_tokens': 98, 'output_tokens': 31, 'total_tokens': 129})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response4 = with_message_history.invoke(\n",
    "    HumanMessage(content=\"What's my Name?\"),\n",
    "    config=config\n",
    ")\n",
    "response4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to remember it! üòä\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 15, 'total_tokens': 54, 'completion_time': 0.070909091, 'prompt_time': 9.111e-05, 'queue_time': 0.013732438999999999, 'total_time': 0.071000201}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f94b4b35-04b1-48dc-bfc5-0d17de8229e4-0', usage_metadata={'input_tokens': 15, 'output_tokens': 39, 'total_tokens': 54})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\": {\"session_id\": \"chat-2\"}}\n",
    "response5 = with_message_history.invoke(\n",
    "    HumanMessage(content=\"What's my Name?\"),\n",
    "    config=config1\n",
    ")\n",
    "response5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with prompt template and message chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ved! üëã  \\n\\nIt's nice to meet you. \\n\\nI'm happy to help with any questions you have. Just ask away! üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 33, 'total_tokens': 71, 'completion_time': 0.069090909, 'prompt_time': 0.001618083, 'queue_time': -0.001587463, 'total_time': 0.070708992}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5302d081-608e-4305-8cbb-15c4eae876dd-0', usage_metadata={'input_tokens': 33, 'output_tokens': 38, 'total_tokens': 71})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are a helpfull assistant answer all the question to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response6 = chain.invoke({\"message\": [HumanMessage(content=\"Hi, My Name is ved.\")]})\n",
    "response6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke with chat message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x000001BAF6BB63B0>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history1 = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history\n",
    ")\n",
    "\n",
    "with_message_history1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\"configurable\": {\"session_id\": \"chat-1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ved Sharma.  I remember!  \\n\\nIs there anything else I can help you with? üòä  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 157, 'total_tokens': 184, 'completion_time': 0.049090909, 'prompt_time': 0.004937601, 'queue_time': 0.009145246000000001, 'total_time': 0.05402851}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9b7ec82e-d3f8-4b12-a29f-1171b81176d9-0', usage_metadata={'input_tokens': 157, 'output_tokens': 27, 'total_tokens': 184})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history1.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Whats my name\")\n",
    "    ],\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§µ‡•á‡§¶, \\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ú‡•ã ‡§≠‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§∏‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ‡•§ \\n\\n‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? üòä \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 36, 'total_tokens': 101, 'completion_time': 0.118181818, 'prompt_time': 0.000305838, 'queue_time': 0.015168712, 'total_time': 0.118487656}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fe47f5f7-5af9-4ee5-b50d-ba6e781737e0-0', usage_metadata={'input_tokens': 36, 'output_tokens': 65, 'total_tokens': 101})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ADDING MORE COMPLEXICITY\n",
    "prompt1 = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"you are a helpfull assistance. answer all the question to the best of your ability in language: {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain1 = prompt1 | model\n",
    "\n",
    "response9 = chain1.invoke(\n",
    "    {\n",
    "        \"message\":[ \"Hi, My name is ved\"],\n",
    "        \"language\": \"Hindi\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ved! üëã \\n\\nIt's nice to meet you.  Is there anything you'd like to talk about or ask me? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 171, 'total_tokens': 205, 'completion_time': 0.061818182, 'prompt_time': 0.006663874, 'queue_time': 0.008755324, 'total_time': 0.068482056}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-87d2641b-9ba0-49ee-bf39-b833ab760303-0', usage_metadata={'input_tokens': 171, 'output_tokens': 34, 'total_tokens': 205})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history2 = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\"\n",
    ")\n",
    "\n",
    "config3 =  {\"configurable\": {\"session_id\": \"chat-3\"}}\n",
    "response7 = with_message_history2.invoke(\n",
    "    {\n",
    "        \"message\": \"Hi, My name is ved\",\n",
    "        \"language\": \"Hindi\"\n",
    "    },\n",
    "    config=config3\n",
    ")\n",
    "response7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ved!  \\n\\nI remember from our last conversation. üòä \\n\\nAnything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 219, 'total_tokens': 247, 'completion_time': 0.050909091, 'prompt_time': 0.006861973, 'queue_time': 0.007672686999999999, 'total_time': 0.057771064}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e72d505a-a472-40ae-bf99-e0f51240ec21-0', usage_metadata={'input_tokens': 219, 'output_tokens': 28, 'total_tokens': 247})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response8 = with_message_history2.invoke(\n",
    "    {\n",
    "        \"message\": \"What's my name?\",\n",
    "        \"language\": \"Hindi\"\n",
    "    },\n",
    "    config=config3\n",
    ")\n",
    "\n",
    "response8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
